import { ChatOpenAI } from '@langchain/openai';
import {
  HumanMessage,
  AIMessage,
  SystemMessage,
  BaseMessage,
  ToolMessage,
  MessageContentComplex,
} from '@langchain/core/messages';

// 1. å®šä¹‰Agenté…ç½®çš„æ•°æ®ç»“æ„
interface AgentConfig {
  id: string;
  name: string;
  emoji: string;
  systemPrompt: string;
  keywords: string[];
}

// 1. å®šä¹‰å›¾ç‰‡åˆ†æå·¥å…·çš„å®Œæ•´ Schema
const analyzeImageTool = {
  type: "function",
  function: {
    name: "analyze_outfit_image",
    description: "åˆ†æç”¨æˆ·ä¸Šä¼ çš„ç©¿æ­ç…§ç‰‡ï¼Œæå–æœè£…ä¿¡æ¯å’Œé£æ ¼ç‰¹å¾ç”¨äºä¸“ä¸šå»ºè®®ã€‚ä»…åœ¨ç”¨æˆ·ä¸Šä¼ äº†å›¾ç‰‡æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚",
    parameters: {
      type: "object",
      properties: {
        clothing_items: {
          type: "array",
          description: "è¯†åˆ«åˆ°çš„å…·ä½“æœè£…å•å“ï¼ˆä¾‹å¦‚ï¼šç™½è‰²Tæ¤ã€è“è‰²ç‰›ä»”è£¤ã€è¿åŠ¨é‹ï¼‰ã€‚",
          items: { type: "string" }
        },
        colors: {
          type: "array",
          description: "å›¾ç‰‡ä¸­çš„ä¸»è¦é¢œè‰²ï¼ˆä¾‹å¦‚ï¼šç±³ç™½è‰²ã€å¤©è“è‰²ã€æ·±ç°è‰²ï¼‰ã€‚",
          items: { type: "string" }
        },
        style_category: {
          type: "string",
          description: "å¯¹æ•´ä½“é£æ ¼çš„åˆ†ç±»ï¼ˆä¾‹å¦‚ï¼šä¼‘é—²ã€å•†åŠ¡ã€å¤å¤ã€è¡—å¤´ï¼‰ã€‚",
        },
        fit_assessment: {
          type: "string",
          description: "å¯¹åˆèº«åº¦çš„è¯„ä¼°ï¼ˆä¾‹å¦‚ï¼šåˆèº«ã€å®½æ¾ã€ä¿®èº«ï¼‰ã€‚"
        },
        occasion_suitability: {
          type: "array",
          description: "è¿™å¥—ç©¿æ­é€‚åˆçš„åœºåˆï¼ˆä¾‹å¦‚ï¼šæ—¥å¸¸é€šå‹¤ã€å‘¨æœ«é€›è¡—ã€æœ‹å‹èšä¼šï¼‰ã€‚",
          items: { type: "string" }
        },
      },
      required: ["clothing_items", "colors", "style_category", "occasion_suitability"]
    }
  }
};

// 2. åˆ›å»ºAgenté…ç½®å¸¸é‡
const AGENTS: Record<string, AgentConfig> = {
  style: {
    id: 'style',
    name: 'å°é›…',
    emoji: 'ğŸ‘—',
    systemPrompt: 'ä½ æ˜¯ä¸“ä¸šçš„ç©¿æ­é¡¾é—®å°é›…ï¼Œæ“…é•¿æ•´ä½“é€ å‹å»ºè®®å’Œé£æ ¼åˆ†æã€‚å½“ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡æ—¶ï¼Œè¯·ä½¿ç”¨`analyze_outfit_image`å·¥å…·æ¥è¾…åŠ©ä½ è¿›è¡Œåˆ†æï¼Œç„¶ååŸºäºåˆ†æç»“æœå’Œä½ çš„ä¸“ä¸šçŸ¥è¯†ç»™å‡ºå»ºè®®ã€‚',
    keywords: ['ç©¿æ­', 'æ­é…', 'é€ å‹', 'é£æ ¼', 'è¡£æœ', 'æœè£…', 'æ—¶å°š'],
  },
  color: {
    id: 'color',
    name: 'å½©è™¹',
    emoji: 'ğŸ¨',
    systemPrompt: 'ä½ æ˜¯è‰²å½©ä¸“å®¶å½©è™¹ï¼Œä¸“æ³¨äºè‰²å½©æ­é…å’Œè‰²å½©ç†è®ºã€‚å½“ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡æ—¶ï¼Œè¯·ä½¿ç”¨`analyze_outfit_image`å·¥å…·æ¥è¾…åŠ©ä½ è¿›è¡Œåˆ†æï¼Œç„¶åé‡ç‚¹ä»è‰²å½©æ­é…ã€è‚¤è‰²é€‚é…ç­‰è§’åº¦ç»™å‡ºä¸“ä¸šå»ºè®®ã€‚',
    keywords: ['é¢œè‰²', 'è‰²å½©', 'é…è‰²', 'è‚¤è‰²', 'è‰²è°ƒ', 'è‰²ç³»'],
  },
  occasion: {
    id: 'occasion',
    name: 'åœºåˆ',
    emoji: 'ğŸ“…',
    systemPrompt: 'ä½ æ˜¯åœºåˆä¸“å®¶åœºåˆï¼Œç²¾é€šä¸åŒåœºåˆçš„ç€è£…è¦æ±‚ã€‚å½“ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡æ—¶ï¼Œè¯·ä½¿ç”¨`analyze_outfit_image`å·¥å…·æ¥è¾…åŠ©ä½ è¿›è¡Œåˆ†æï¼Œç„¶åé‡ç‚¹è¯„ä¼°è¿™å¥—ç©¿æ­çš„åœºåˆé€‚é…æ€§ã€‚',
    keywords: ['çº¦ä¼š', 'ä¸Šç­', 'å·¥ä½œ', 'èšä¼š', 'åœºåˆ', 'å©šç¤¼', 'é¢è¯•', 'èŒåœº', 'æ­£å¼', 'ä¼‘é—²'],
  },
};

// 3. åˆ›å»ºAgenté€‰æ‹©å‡½æ•°
const selectAgent = (userMessage: string): AgentConfig => {
  const message = userMessage.toLowerCase();
  let bestAgentId = 'style'; // é»˜è®¤
  let maxScore = 0;

  for (const [agentId, config] of Object.entries(AGENTS)) {
    let score = 0;
    for (const keyword of config.keywords) {
      if (message.includes(keyword)) {
        score++;
      }
    }
    if (score > maxScore) {
      maxScore = score;
      bestAgentId = agentId;
    }
  }
  return AGENTS[bestAgentId];
};

export class ChatAgent {
  private llm: ChatOpenAI;
  private memory: BaseMessage[] = []; // 1. Add back memory property

  constructor() {
    this.llm = new ChatOpenAI({ modelName: 'gpt-4o', temperature: 0.7 });
  }

  public async chat(
    message: string,
    imageUrl?: string, // 2. Remove history parameter
  ): Promise<{ agentInfo: AgentConfig; aiResponse: string }> {
    console.log(`[ChatAgent] Received chat request. Message: "${message}", Image URL: ${!!imageUrl}`);

    const selectedAgent = this.selectAgent(message);
    console.log(`[ChatAgent] Selected agent: ${selectedAgent.name}`);
    const systemMessage = new SystemMessage(selectedAgent.systemPrompt);

    const pastMessages = this.memory; // 3. Use internal memory

    // Correctly build the multi-modal message content
    const userMessageContent: MessageContentComplex[] = [{ type: "text", text: message }];
    if (imageUrl) {
      userMessageContent.push({
        type: "image_url",
        image_url: { url: imageUrl },
      });
    }
    const userMessage = new HumanMessage({ content: userMessageContent });


    const messages: BaseMessage[] = [systemMessage, ...pastMessages, userMessage];

    // 4. å¦‚æœæœ‰å›¾ç‰‡ï¼ŒåŠ¨æ€æ·»åŠ  tool call ç›¸å…³å‚æ•°
    const llmOptions: any = {};
    if (imageUrl) {
      llmOptions.tools = [analyzeImageTool];
      llmOptions.tool_choice = { type: "function", function: { name: "analyze_outfit_image" } };
      console.log('[ChatAgent] Image detected. Adding image analysis tool to LLM call.');
    }

    // 5. ç¬¬ä¸€æ¬¡è°ƒç”¨ LLM
    const firstResponse = await this.llm.invoke(messages, llmOptions);
    console.log('[ChatAgent] First LLM call complete.');

    // Check and handle tool_calls
    if (firstResponse.tool_calls && firstResponse.tool_calls.length > 0) {
      console.log("[ChatAgent] Tool call detected:", JSON.stringify(firstResponse.tool_calls, null, 2));
      const toolCall = firstResponse.tool_calls[0];

      // 3. Add a guard clause for the tool call ID
      if (!toolCall.id) {
        console.warn("Tool call received without an ID, returning direct response.");
        return {
          agentInfo: selectedAgent,
          aiResponse: firstResponse.content.toString(),
        };
      }

      const toolCallId = toolCall.id;
      const toolFunctionName = toolCall.name;
      const toolArgs = toolCall.args;

      // åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œè¿™é‡Œä¼šè°ƒç”¨ä¸€ä¸ªçœŸå®çš„å›¾ç‰‡åˆ†ææœåŠ¡
      // åœ¨MVPé˜¶æ®µï¼Œæˆ‘ä»¬è®©LLMè‡ªå·±ç”Ÿæˆåˆ†æç»“æœï¼Œç„¶åå°†å…¶ä½œä¸ºToolçš„è¾“å‡º
      // è¿™ä¸ª "output" å°±æ˜¯æˆ‘ä»¬ä¹‹å‰å®šä¹‰çš„schemaæ ¼å¼çš„JSON
      const toolOutput = JSON.stringify(toolArgs);
      console.log(`[ChatAgent] Simulated tool output for "${toolFunctionName}":`, toolOutput);

      const toolMessage = new ToolMessage({
        tool_call_id: toolCallId,
        name: toolFunctionName,
        content: toolOutput,
      });

      // 7. å°† tool_call çš„ç»“æœå’ŒåŸå§‹è¯·æ±‚ä¸€èµ·å†æ¬¡å‘é€ç»™LLM
      const messagesForSecondCall: BaseMessage[] = [
        systemMessage,
        ...pastMessages,
        userMessage,
        firstResponse, // åŒ…å« tool_call è¯·æ±‚çš„ AI æ¶ˆæ¯
        toolMessage,   // åŒ…å« tool_call ç»“æœçš„æ¶ˆæ¯
      ];

      console.log('[ChatAgent] Making second LLM call with tool results...');
      const finalResponse = await this.llm.invoke(messagesForSecondCall);
      console.log('[ChatAgent] Second LLM call complete.');

      // 4. Update memory after tool call
      this.memory.push(userMessage);
      this.memory.push(finalResponse);

      return {
        agentInfo: selectedAgent,
        aiResponse: finalResponse.content.toString(),
      };
    }

    // 5. Update memory for simple response
    this.memory.push(userMessage);
    this.memory.push(firstResponse);

    console.log(`[ChatAgent] Responding with simple text. Length: ${firstResponse.content.toString().length}`);
    return {
      agentInfo: selectedAgent,
      aiResponse: firstResponse.content.toString(),
    };
  }

  private selectAgent(message: string): AgentConfig {
    return selectAgent(message);
  }
}