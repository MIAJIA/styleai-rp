import { ChatOpenAI } from '@langchain/openai';
import {
  HumanMessage,
  AIMessage,
  SystemMessage,
  BaseMessage,
  ToolMessage,
  MessageContentComplex,
} from '@langchain/core/messages';
import { SmartContextManager } from './memory';

// 1. å®šä¹‰Agenté…ç½®çš„æ•°æ®ç»“æ„
interface AgentConfig {
  id: string;
  name: string;
  emoji: string;
  systemPrompt: string;
  keywords: string[];
}

// 1. å®šä¹‰å›¾ç‰‡åˆ†æå·¥å…·çš„å®Œæ•´ Schema
const analyzeImageTool = {
  type: "function",
  function: {
    name: "analyze_outfit_image",
    description: "åˆ†æç”¨æˆ·ä¸Šä¼ çš„ç©¿æ­ç…§ç‰‡ï¼Œæå–æœè£…ä¿¡æ¯å’Œé£æ ¼ç‰¹å¾ç”¨äºä¸“ä¸šå»ºè®®ã€‚ä»…åœ¨ç”¨æˆ·ä¸Šä¼ äº†å›¾ç‰‡æ—¶ä½¿ç”¨æ­¤å·¥å…·ã€‚",
    parameters: {
      type: "object",
      properties: {
        clothing_items: {
          type: "array",
          description: "è¯†åˆ«åˆ°çš„å…·ä½“æœè£…å•å“ï¼ˆä¾‹å¦‚ï¼šç™½è‰²Tæ¤ã€è“è‰²ç‰›ä»”è£¤ã€è¿åŠ¨é‹ï¼‰ã€‚",
          items: { type: "string" }
        },
        colors: {
          type: "array",
          description: "å›¾ç‰‡ä¸­çš„ä¸»è¦é¢œè‰²ï¼ˆä¾‹å¦‚ï¼šç±³ç™½è‰²ã€å¤©è“è‰²ã€æ·±ç°è‰²ï¼‰ã€‚",
          items: { type: "string" }
        },
        style_category: {
          type: "string",
          description: "å¯¹æ•´ä½“é£æ ¼çš„åˆ†ç±»ï¼ˆä¾‹å¦‚ï¼šä¼‘é—²ã€å•†åŠ¡ã€å¤å¤ã€è¡—å¤´ï¼‰ã€‚",
        },
        fit_assessment: {
          type: "string",
          description: "å¯¹åˆèº«åº¦çš„è¯„ä¼°ï¼ˆä¾‹å¦‚ï¼šåˆèº«ã€å®½æ¾ã€ä¿®èº«ï¼‰ã€‚"
        },
        occasion_suitability: {
          type: "array",
          description: "è¿™å¥—ç©¿æ­é€‚åˆçš„åœºåˆï¼ˆä¾‹å¦‚ï¼šæ—¥å¸¸é€šå‹¤ã€å‘¨æœ«é€›è¡—ã€æœ‹å‹èšä¼šï¼‰ã€‚",
          items: { type: "string" }
        },
      },
      required: ["clothing_items", "colors", "style_category", "occasion_suitability"]
    }
  }
};

// 2. åˆ›å»ºAgenté…ç½®å¸¸é‡
const AGENTS: Record<string, AgentConfig> = {
  style: {
    id: 'style',
    name: 'å°é›…',
    emoji: 'ğŸ‘—',
    systemPrompt: 'ä½ æ˜¯ä¸“ä¸šçš„ç©¿æ­é¡¾é—®å°é›…ï¼Œæ“…é•¿æ•´ä½“é€ å‹å»ºè®®å’Œé£æ ¼åˆ†æã€‚å½“ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡æ—¶ï¼Œè¯·ä½¿ç”¨`analyze_outfit_image`å·¥å…·æ¥è¾…åŠ©ä½ è¿›è¡Œåˆ†æï¼Œç„¶ååŸºäºåˆ†æç»“æœå’Œä½ çš„ä¸“ä¸šçŸ¥è¯†ç»™å‡ºå»ºè®®ã€‚',
    keywords: ['ç©¿æ­', 'æ­é…', 'é€ å‹', 'é£æ ¼', 'è¡£æœ', 'æœè£…', 'æ—¶å°š'],
  },
  color: {
    id: 'color',
    name: 'å½©è™¹',
    emoji: 'ğŸ¨',
    systemPrompt: 'ä½ æ˜¯è‰²å½©ä¸“å®¶å½©è™¹ï¼Œä¸“æ³¨äºè‰²å½©æ­é…å’Œè‰²å½©ç†è®ºã€‚å½“ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡æ—¶ï¼Œè¯·ä½¿ç”¨`analyze_outfit_image`å·¥å…·æ¥è¾…åŠ©ä½ è¿›è¡Œåˆ†æï¼Œç„¶åé‡ç‚¹ä»è‰²å½©æ­é…ã€è‚¤è‰²é€‚é…ç­‰è§’åº¦ç»™å‡ºä¸“ä¸šå»ºè®®ã€‚',
    keywords: ['é¢œè‰²', 'è‰²å½©', 'é…è‰²', 'è‚¤è‰²', 'è‰²è°ƒ', 'è‰²ç³»'],
  },
  occasion: {
    id: 'occasion',
    name: 'åœºåˆ',
    emoji: 'ğŸ“…',
    systemPrompt: 'ä½ æ˜¯åœºåˆä¸“å®¶åœºåˆï¼Œç²¾é€šä¸åŒåœºåˆçš„ç€è£…è¦æ±‚ã€‚å½“ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡æ—¶ï¼Œè¯·ä½¿ç”¨`analyze_outfit_image`å·¥å…·æ¥è¾…åŠ©ä½ è¿›è¡Œåˆ†æï¼Œç„¶åé‡ç‚¹è¯„ä¼°è¿™å¥—ç©¿æ­çš„åœºåˆé€‚é…æ€§ã€‚',
    keywords: ['çº¦ä¼š', 'ä¸Šç­', 'å·¥ä½œ', 'èšä¼š', 'åœºåˆ', 'å©šç¤¼', 'é¢è¯•', 'èŒåœº', 'æ­£å¼', 'ä¼‘é—²'],
  },
};

// 3. åˆ›å»ºAgenté€‰æ‹©å‡½æ•°
const selectAgent = (userMessage: string): AgentConfig => {
  const message = userMessage.toLowerCase();
  let bestAgentId = 'style'; // é»˜è®¤
  let maxScore = 0;

  for (const [agentId, config] of Object.entries(AGENTS)) {
    let score = 0;
    for (const keyword of config.keywords) {
      if (message.includes(keyword)) {
        score++;
      }
    }
    if (score > maxScore) {
      maxScore = score;
      bestAgentId = agentId;
    }
  }
  return AGENTS[bestAgentId];
};

export class ChatAgent {
  private llm: ChatOpenAI;
  private contextManager: SmartContextManager;

  constructor() {
    this.llm = new ChatOpenAI({
      modelName: 'gpt-4o',
      temperature: 0.7,
      maxTokens: 1000,
    });
    this.contextManager = new SmartContextManager();
  }

  // æ–°å¢æ–¹æ³•ï¼šæ·»åŠ ç”Ÿæˆçš„å›¾ç‰‡åˆ°ä¸Šä¸‹æ–‡
  public addGeneratedImageToContext(imageUrl: string) {
    console.log('[ChatAgent] Adding generated image to context:', imageUrl);

    // æ·»åŠ AIç”Ÿæˆçš„å›¾ç‰‡æ¶ˆæ¯åˆ°ä¸Šä¸‹æ–‡
    this.contextManager.addMessage('ai', 'ğŸ‰ æ‚¨çš„ç©¿æ­ç”Ÿæˆå·²å®Œæˆï¼', imageUrl, {
      type: 'style',
      name: 'å°é›…',
      emoji: 'ğŸ‘—'
    });

    console.log('[ChatAgent] Generated image added to context successfully');
  }

  public async chat(
    message: string,
    imageUrl?: string,
  ): Promise<{ agentInfo: AgentConfig; aiResponse: string }> {
    console.log(`[ChatAgent] Processing message with context awareness`);

    this.contextManager.addMessage('user', message, imageUrl);

    const needsContext = this.contextManager.shouldIncludeContext(message);
    console.log(`[ChatAgent] Needs context: ${needsContext}`);

    const selectedAgent = this.selectAgent(message, !!imageUrl);
    console.log(`[ChatAgent] Selected agent: ${selectedAgent.name}`);

    let systemPrompt = selectedAgent.systemPrompt;
    if (needsContext) {
      const contextPrompt = this.contextManager.generateContextPrompt();
      systemPrompt += contextPrompt;
      console.log('[ChatAgent] Including conversation context in prompt');
    }
    console.log(`[ChatAgent] Final system prompt: ${systemPrompt}`);
    const systemMessage = new SystemMessage(systemPrompt);

    const userMessageContent: MessageContentComplex[] = [{ type: "text", text: message }];

    // æ£€æŸ¥æ˜¯å¦æœ‰å›¾ç‰‡ - å½“å‰æ¶ˆæ¯æˆ–ä¸Šä¸‹æ–‡ä¸­çš„å›¾ç‰‡
    const hasCurrentImage = !!imageUrl;
    const hasContextImage = this.contextManager.hasRecentImage();
    const shouldUseImageTool = hasCurrentImage || hasContextImage;

    if (hasCurrentImage) {
      userMessageContent.push({
        type: "image_url",
        image_url: { url: imageUrl },
      });
    } else if (hasContextImage && needsContext) {
      // å¦‚æœå½“å‰æ¶ˆæ¯æ²¡æœ‰å›¾ç‰‡ä½†ä¸Šä¸‹æ–‡æœ‰å›¾ç‰‡ï¼Œæ·»åŠ ä¸Šä¸‹æ–‡ä¸­çš„å›¾ç‰‡
      const contextImageUrl = this.contextManager.getLastUploadedImage();
      if (contextImageUrl) {
        userMessageContent.push({
          type: "image_url",
          image_url: { url: contextImageUrl },
        });
        console.log('[ChatAgent] Adding context image to current message for analysis');
      }
    }

    const userMessage = new HumanMessage({ content: userMessageContent });
    const messages: BaseMessage[] = [systemMessage, userMessage];

    const llmOptions: any = {};
    if (shouldUseImageTool) {
      llmOptions.tools = [analyzeImageTool];
      llmOptions.tool_choice = { type: "function", function: { name: "analyze_outfit_image" } };
      console.log('[ChatAgent] Image detected (current or context). Adding image analysis tool to LLM call.');
    }

    const firstResponse = await this.llm.invoke(messages, llmOptions);
    console.log('[ChatAgent] First LLM call complete.');

    if (firstResponse.tool_calls && firstResponse.tool_calls.length > 0) {
      console.log("[ChatAgent] Tool call detected:", JSON.stringify(firstResponse.tool_calls, null, 2));
      const toolCall = firstResponse.tool_calls[0];

      if (!toolCall.id) {
        console.warn("Tool call received without an ID, returning direct response.");
        this.contextManager.addMessage('ai', firstResponse.content.toString(), undefined, {
          type: selectedAgent.id,
          name: selectedAgent.name,
          emoji: selectedAgent.emoji
        });
        return {
          agentInfo: selectedAgent,
          aiResponse: firstResponse.content.toString(),
        };
      }

      const toolCallId = toolCall.id;
      const toolFunctionName = toolCall.name;
      const toolArgs = toolCall.args;
      const toolOutput = JSON.stringify(toolArgs);
      console.log(`[ChatAgent] Simulated tool output for "${toolFunctionName}":`, toolOutput);

      const toolMessage = new ToolMessage({
        tool_call_id: toolCallId,
        name: toolFunctionName,
        content: toolOutput,
      });

      const messagesForSecondCall: BaseMessage[] = [
        systemMessage,
        userMessage,
        firstResponse,
        toolMessage,
      ];

      console.log('[ChatAgent] Making second LLM call with tool results...');
      const finalResponse = await this.llm.invoke(messagesForSecondCall);
      console.log('[ChatAgent] Second LLM call complete.');

      this.contextManager.addMessage('ai', finalResponse.content.toString(), undefined, {
        type: selectedAgent.id,
        name: selectedAgent.name,
        emoji: selectedAgent.emoji
      });

      return {
        agentInfo: selectedAgent,
        aiResponse: finalResponse.content.toString(),
      };
    }

    this.contextManager.addMessage('ai', firstResponse.content.toString(), undefined, {
      type: selectedAgent.id,
      name: selectedAgent.name,
      emoji: selectedAgent.emoji
    });

    console.log(`[ChatAgent] Responding with simple text. Length: ${firstResponse.content.toString().length}`);
    return {
      agentInfo: selectedAgent,
      aiResponse: firstResponse.content.toString(),
    };
  }

  private selectAgent(message: string, hasImage?: boolean): AgentConfig {
    // Note: The original logic in the file did not use hasImage, so I'm keeping it that way.
    // The design doc says "ç°æœ‰çš„Agenté€‰æ‹©é€»è¾‘ä¿æŒä¸å˜"
    return selectAgent(message);
  }
}